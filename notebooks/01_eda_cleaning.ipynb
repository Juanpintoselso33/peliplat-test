{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración Inicial y Limpieza de Datos\n",
    "\n",
    "Notebook destinada al análisis exploratorio y proceso de limpieza de los datasets de Peliplat. Este proceso sigue metodologías ETL estándar para garantizar la calidad de los datos antes de su análisis posterior.\n",
    "\n",
    "**Objetivos:**\n",
    "- Explorar la estructura y calidad de los datasets de Peliplat\n",
    "- Identificar y corregir problemas de codificación, duplicados y outliers\n",
    "- Normalizar formatos de fecha y referencias entre datasets\n",
    "- Preparar datos limpios para análisis posteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup inicial\n",
    "\n",
    "En esta sección se importan las librerías necesarias y se cargan los datasets crudos. Se utiliza un enfoque modular importando funciones específicas del módulo `cleaning.py` para mantener el código organizado y reutilizable.\n",
    "\n",
    "Los datasets cargados son:\n",
    "- `users`: Información demográfica de usuarios\n",
    "- `activity`: Métricas de actividad y comportamiento\n",
    "- `campaigns`: Datos de campañas de marketing\n",
    "- `content`: Catálogo de contenido disponible\n",
    "- `engagement`: Interacciones de usuarios con el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.cleaning import fix_encoding, cast_dates, remove_duplicates, process_outliers, save_processed_data, fix_temporal_inconsistencies\n",
    "\n",
    "\n",
    "# Cargar datasets\n",
    "users = pd.read_csv('../data/raw/peliplat_users.csv', encoding='latin1')\n",
    "activity = pd.read_csv('../data/raw/peliplat_activity.csv', encoding='latin1')\n",
    "campaigns = pd.read_csv('../data/raw/peliplat_campaigns.csv', encoding='latin1')\n",
    "content = pd.read_csv('../data/raw/peliplat_content.csv', encoding='latin1')\n",
    "engagement = pd.read_csv('../data/raw/peliplat_engagement.csv', encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración General Inicial\n",
    "\n",
    "Esta sección realiza un análisis preliminar de los datasets para conocer su estructura y características principales. Para cada dataset se examina:\n",
    "\n",
    "- Vista previa de las primeras filas (head)\n",
    "- Estructura y tipos de datos (info)\n",
    "- Detección de valores nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset users:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>last_active</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>Chile</td>\n",
       "      <td>2025-03-11</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>Perú</td>\n",
       "      <td>2025-01-11</td>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>Perú</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>Perú</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>Other</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id   country signup_date last_active  gender  age\n",
       "0   U0000     Chile  2025-03-11  2025-03-17    Male   51\n",
       "1   U0001      Perú  2025-01-11  2025-03-30  Female   55\n",
       "2   U0002  Colombia  2025-01-16  2025-03-14    Male   51\n",
       "3   U0003      Perú  2025-03-14  2025-03-30  Female   35\n",
       "4   U0004      Perú  2025-02-28  2025-03-20   Other   47"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      200 non-null    object\n",
      " 1   country      200 non-null    object\n",
      " 2   signup_date  200 non-null    object\n",
      " 3   last_active  200 non-null    object\n",
      " 4   gender       200 non-null    object\n",
      " 5   age          200 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "user_id        0\n",
      "country        0\n",
      "signup_date    0\n",
      "last_active    0\n",
      "gender         0\n",
      "age            0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "Dataset activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_daily_visits</th>\n",
       "      <th>avg_time_on_page</th>\n",
       "      <th>most_viewed_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>261.7</td>\n",
       "      <td>Lista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>0.57</td>\n",
       "      <td>261.7</td>\n",
       "      <td>ArtÃ­culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>2.68</td>\n",
       "      <td>261.7</td>\n",
       "      <td>Video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>0.97</td>\n",
       "      <td>261.7</td>\n",
       "      <td>Lista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>0.83</td>\n",
       "      <td>261.7</td>\n",
       "      <td>Lista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  avg_daily_visits  avg_time_on_page most_viewed_type\n",
       "0   U0000              0.83             261.7            Lista\n",
       "1   U0001              0.57             261.7        ArtÃ­culo\n",
       "2   U0002              2.68             261.7            Video\n",
       "3   U0003              0.97             261.7            Lista\n",
       "4   U0004              0.83             261.7            Lista"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   user_id           200 non-null    object \n",
      " 1   avg_daily_visits  200 non-null    float64\n",
      " 2   avg_time_on_page  200 non-null    float64\n",
      " 3   most_viewed_type  200 non-null    object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "user_id             0\n",
      "avg_daily_visits    0\n",
      "avg_time_on_page    0\n",
      "most_viewed_type    0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "Dataset campaigns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>clicks</th>\n",
       "      <th>signups</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP00</td>\n",
       "      <td>CampaÃ±a_1</td>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>2025-01-20</td>\n",
       "      <td>961</td>\n",
       "      <td>128</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP01</td>\n",
       "      <td>CampaÃ±a_2</td>\n",
       "      <td>2025-01-25</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>353</td>\n",
       "      <td>70</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP02</td>\n",
       "      <td>CampaÃ±a_3</td>\n",
       "      <td>2025-02-10</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>729</td>\n",
       "      <td>166</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP03</td>\n",
       "      <td>CampaÃ±a_4</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>809</td>\n",
       "      <td>189</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP04</td>\n",
       "      <td>CampaÃ±a_5</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>948</td>\n",
       "      <td>54</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  campaign_id        name  start_date    end_date  clicks  signups    CTR\n",
       "0        CP00  CampaÃ±a_1  2025-01-10  2025-01-20     961      128  0.114\n",
       "1        CP01  CampaÃ±a_2  2025-01-25  2025-02-05     353       70  0.181\n",
       "2        CP02  CampaÃ±a_3  2025-02-10  2025-02-18     729      166  0.176\n",
       "3        CP03  CampaÃ±a_4  2025-02-20  2025-02-28     809      189  0.078\n",
       "4        CP04  CampaÃ±a_5  2025-03-10  2025-03-25     948       54  0.170"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   campaign_id  5 non-null      object \n",
      " 1   name         5 non-null      object \n",
      " 2   start_date   5 non-null      object \n",
      " 3   end_date     5 non-null      object \n",
      " 4   clicks       5 non-null      int64  \n",
      " 5   signups      5 non-null      int64  \n",
      " 6   CTR          5 non-null      float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 412.0+ bytes\n",
      "None\n",
      "campaign_id    0\n",
      "name           0\n",
      "start_date     0\n",
      "end_date       0\n",
      "clicks         0\n",
      "signups        0\n",
      "CTR            0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "Dataset content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>creator_id</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000</td>\n",
       "      <td>CR21</td>\n",
       "      <td>ArtÃ­culo</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0001</td>\n",
       "      <td>CR4</td>\n",
       "      <td>ArtÃ­culo</td>\n",
       "      <td>Documental</td>\n",
       "      <td>2025-01-30</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0002</td>\n",
       "      <td>CR1</td>\n",
       "      <td>Lista</td>\n",
       "      <td>Documental</td>\n",
       "      <td>2025-01-25</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0003</td>\n",
       "      <td>CR24</td>\n",
       "      <td>Lista</td>\n",
       "      <td>ClÃ¡sicos</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0004</td>\n",
       "      <td>CR9</td>\n",
       "      <td>Lista</td>\n",
       "      <td>ClÃ¡sicos</td>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content_id creator_id       type    category publish_date  visits\n",
       "0      C0000       CR21  ArtÃ­culo  Mainstream   2025-01-10      48\n",
       "1      C0001        CR4  ArtÃ­culo  Documental   2025-01-30      55\n",
       "2      C0002        CR1      Lista  Documental   2025-01-25      61\n",
       "3      C0003       CR24      Lista   ClÃ¡sicos   2025-03-25      55\n",
       "4      C0004        CR9      Lista   ClÃ¡sicos   2025-01-05      39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   content_id    300 non-null    object\n",
      " 1   creator_id    300 non-null    object\n",
      " 2   type          300 non-null    object\n",
      " 3   category      300 non-null    object\n",
      " 4   publish_date  300 non-null    object\n",
      " 5   visits        300 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.2+ KB\n",
      "None\n",
      "content_id      0\n",
      "creator_id      0\n",
      "type            0\n",
      "category        0\n",
      "publish_date    0\n",
      "visits          0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "Dataset engagement:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>likes</th>\n",
       "      <th>shares</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0073</td>\n",
       "      <td>C0048</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0191</td>\n",
       "      <td>C0189</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0004</td>\n",
       "      <td>C0135</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0099</td>\n",
       "      <td>C0042</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0069</td>\n",
       "      <td>C0089</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id content_id  likes  shares  comments\n",
       "0   U0073      C0048      2       1         0\n",
       "1   U0191      C0189      3       1         1\n",
       "2   U0004      C0135      3       0         1\n",
       "3   U0099      C0042      3       1         2\n",
       "4   U0069      C0089      2       0         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user_id     500 non-null    object\n",
      " 1   content_id  500 non-null    object\n",
      " 2   likes       500 non-null    int64 \n",
      " 3   shares      500 non-null    int64 \n",
      " 4   comments    500 non-null    int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 19.7+ KB\n",
      "None\n",
      "user_id       0\n",
      "content_id    0\n",
      "likes         0\n",
      "shares        0\n",
      "comments      0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Revisión rápida\n",
    "datasets = {'users': users, 'activity': activity, 'campaigns': campaigns, 'content': content, 'engagement': engagement}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Dataset {name}:\")\n",
    "    display(df.head())\n",
    "    print(df.info())\n",
    "    print(df.isna().sum())\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpieza \n",
    "\n",
    "Esta sección implementa un proceso sistemático de limpieza de datos, aplicando técnicas estándar de la industria para garantizar la integridad y consistencia de los datasets. Se utilizan funciones modularizadas del módulo `cleaning.py` para mantener el código organizado y reproducible.\n",
    "\n",
    "El proceso de limpieza sigue una secuencia lógica que aborda diferentes tipos de problemas de calidad de datos, comenzando por los más fundamentales (codificación) hasta los más específicos (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Limpieza de codificación\n",
    "\n",
    "Esta etapa corrige problemas de codificación de caracteres en campos de texto, principalmente caracteres especiales del español (tildes, eñes) que aparecen mal codificados. Se utiliza la función `fix_encoding` que implementa la biblioteca `ftfy` (Fixes Text For You) para detectar y corregir automáticamente estos problemas.\n",
    "\n",
    "La biblioteca `ftfy` es una herramienta especializada en reparación de texto que:\n",
    "- Detecta y corrige problemas comunes de codificación UTF-8\n",
    "- Resuelve problemas de texto que ha sido codificado múltiples veces\n",
    "- Normaliza caracteres compuestos a su forma canónica\n",
    "\n",
    "Problemas principales detectados y corregidos:\n",
    "- \"ArtÃ­culo\" → \"Artículo\" \n",
    "- \"CampaÃ±a\" → \"Campaña\"\n",
    "- \"ClÃ¡sicos\" → \"Clásicos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALORES ÚNICOS ANTES DE LA CORRECCIÓN ===\n",
      "\n",
      "--- USUARIOS (ORIGINAL) ---\n",
      "Country únicos:\n",
      "['Chile' 'Perú' 'Colombia' 'México' 'Argentina']\n",
      "\n",
      "Gender únicos:\n",
      "['Male' 'Female' 'Other']\n",
      "\n",
      "--- ACTIVIDAD (ORIGINAL) ---\n",
      "Most viewed type únicos:\n",
      "['Lista' 'ArtÃ\\xadculo' 'Video']\n",
      "\n",
      "--- CAMPAÑAS (ORIGINAL) ---\n",
      "Nombre de campañas únicos:\n",
      "['CampaÃ±a_1' 'CampaÃ±a_2' 'CampaÃ±a_3' 'CampaÃ±a_4' 'CampaÃ±a_5']\n",
      "\n",
      "--- CONTENIDO (ORIGINAL) ---\n",
      "Tipos de contenido únicos:\n",
      "['ArtÃ\\xadculo' 'Lista' 'Video']\n",
      "\n",
      "Categorías únicas:\n",
      "['Mainstream' 'Documental' 'ClÃ¡sicos' 'Indie']\n",
      "\n",
      "\n",
      "=== VALORES ÚNICOS DESPUÉS DE LA CORRECCIÓN ===\n",
      "\n",
      "--- USUARIOS (CORREGIDOS) ---\n",
      "Country únicos (corregidos):\n",
      "['Chile' 'Perú' 'Colombia' 'México' 'Argentina']\n",
      "\n",
      "Gender únicos (corregidos):\n",
      "['Male' 'Female' 'Other']\n",
      "\n",
      "--- ACTIVIDAD (CORREGIDA) ---\n",
      "Most viewed type únicos (corregidos):\n",
      "['Lista' 'Artículo' 'Video']\n",
      "\n",
      "--- CAMPAÑAS (CORREGIDAS) ---\n",
      "Nombre de campañas únicos (corregidos):\n",
      "['Campaña_1' 'Campaña_2' 'Campaña_3' 'Campaña_4' 'Campaña_5']\n",
      "\n",
      "--- CONTENIDO (CORREGIDO) ---\n",
      "Tipos de contenido únicos (corregidos):\n",
      "['Artículo' 'Lista' 'Video']\n",
      "\n",
      "Categorías únicas (corregidas):\n",
      "['Mainstream' 'Documental' 'Clásicos' 'Indie']\n"
     ]
    }
   ],
   "source": [
    "# Guardar una copia de los valores únicos ANTES de aplicar correcciones\n",
    "print(\"=== VALORES ÚNICOS ANTES DE LA CORRECCIÓN ===\")\n",
    "\n",
    "print(\"\\n--- USUARIOS (ORIGINAL) ---\")\n",
    "print(\"Country únicos:\")\n",
    "print(users['country'].unique())\n",
    "print(\"\\nGender únicos:\")\n",
    "print(users['gender'].unique())\n",
    "\n",
    "print(\"\\n--- ACTIVIDAD (ORIGINAL) ---\")\n",
    "print(\"Most viewed type únicos:\")\n",
    "print(activity['most_viewed_type'].unique())\n",
    "\n",
    "print(\"\\n--- CAMPAÑAS (ORIGINAL) ---\")\n",
    "print(\"Nombre de campañas únicos:\")\n",
    "print(campaigns['name'].unique())\n",
    "\n",
    "print(\"\\n--- CONTENIDO (ORIGINAL) ---\")\n",
    "print(\"Tipos de contenido únicos:\")\n",
    "print(content['type'].unique())\n",
    "print(\"\\nCategorías únicas:\")\n",
    "print(content['category'].unique())\n",
    "\n",
    "# Aplicar la función fix_encoding a todos los dataframes\n",
    "users_clean = fix_encoding(users)\n",
    "activity_clean = fix_encoding(activity)\n",
    "campaigns_clean = fix_encoding(campaigns)\n",
    "content_clean = fix_encoding(content)\n",
    "engagement_clean = fix_encoding(engagement)\n",
    "\n",
    "print(\"\\n\\n=== VALORES ÚNICOS DESPUÉS DE LA CORRECCIÓN ===\")\n",
    "\n",
    "print(\"\\n--- USUARIOS (CORREGIDOS) ---\")\n",
    "print(\"Country únicos (corregidos):\")\n",
    "print(users_clean['country'].unique())\n",
    "print(\"\\nGender únicos (corregidos):\")\n",
    "print(users_clean['gender'].unique())\n",
    "\n",
    "print(\"\\n--- ACTIVIDAD (CORREGIDA) ---\")\n",
    "print(\"Most viewed type únicos (corregidos):\")\n",
    "print(activity_clean['most_viewed_type'].unique())\n",
    "\n",
    "print(\"\\n--- CAMPAÑAS (CORREGIDAS) ---\")\n",
    "print(\"Nombre de campañas únicos (corregidos):\")\n",
    "print(campaigns_clean['name'].unique())\n",
    "\n",
    "print(\"\\n--- CONTENIDO (CORREGIDO) ---\")\n",
    "print(\"Tipos de contenido únicos (corregidos):\")\n",
    "print(content_clean['type'].unique())\n",
    "print(\"\\nCategorías únicas (corregidas):\")\n",
    "print(content_clean['category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Convertir fechas usando la función cast_dates\n",
    "\n",
    "En esta etapa se convierten las columnas de tipo texto que contienen fechas a objetos datetime de pandas (formato datetime64[ns]). Este proceso es crucial ya que:\n",
    "\n",
    "- Permite realizar operaciones temporales (diferencias, rangos, filtros)\n",
    "- Facilita el análisis de tendencias y patrones temporales\n",
    "- Habilita la detección de inconsistencias en datos cronológicos\n",
    "\n",
    "Se procesan las siguientes columnas de fecha en cada dataset:\n",
    "- **users**: 'signup_date', 'last_active'\n",
    "- **campaigns**: 'start_date', 'end_date'\n",
    "- **content**: 'publish_date'\n",
    "\n",
    "La conversión se realiza de manera uniforme mediante la función `cast_dates`, que utiliza internamente `pd.to_datetime()` con gestión de errores para garantizar la integridad de los datos. Aunque las fechas ya se encontraban en formato ISO (YYYY-MM-DD), esta conversión es necesaria para habilitar operaciones de análisis temporal.### 3.2 Convertir fechas usando la función cast_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE CONVERSIÓN DE FECHAS ===\n",
      "\n",
      "--- USUARIOS ---\n",
      "Antes de la conversión:\n",
      "0   2025-03-11\n",
      "1   2025-01-11\n",
      "2   2025-01-16\n",
      "3   2025-03-14\n",
      "4   2025-02-28\n",
      "Name: signup_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "\n",
      "Después de la conversión:\n",
      "0   2025-03-11\n",
      "1   2025-01-11\n",
      "2   2025-01-16\n",
      "3   2025-03-14\n",
      "4   2025-02-28\n",
      "Name: signup_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "\n",
      "--- CAMPAÑAS ---\n",
      "Antes de la conversión:\n",
      "0   2025-01-10\n",
      "1   2025-01-25\n",
      "2   2025-02-10\n",
      "3   2025-02-20\n",
      "4   2025-03-10\n",
      "Name: start_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "\n",
      "Después de la conversión:\n",
      "0   2025-01-10\n",
      "1   2025-01-25\n",
      "2   2025-02-10\n",
      "3   2025-02-20\n",
      "4   2025-03-10\n",
      "Name: start_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "\n",
      "--- CONTENIDO ---\n",
      "Antes de la conversión:\n",
      "0   2025-01-10\n",
      "1   2025-01-30\n",
      "2   2025-01-25\n",
      "3   2025-03-25\n",
      "4   2025-01-05\n",
      "Name: publish_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n",
      "\n",
      "Después de la conversión:\n",
      "0   2025-01-10\n",
      "1   2025-01-30\n",
      "2   2025-01-25\n",
      "3   2025-03-25\n",
      "4   2025-01-05\n",
      "Name: publish_date, dtype: datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Columnas con fechas en cada dataframe\n",
    "users_date_cols = ['signup_date', 'last_active']\n",
    "campaigns_date_cols = ['start_date', 'end_date']\n",
    "content_date_cols = ['publish_date']\n",
    "\n",
    "# Aplicar la función cast_dates a los dataframes limpios\n",
    "users_clean = cast_dates(users_clean, users_date_cols)\n",
    "campaigns_clean = cast_dates(campaigns_clean, campaigns_date_cols)\n",
    "content_clean = cast_dates(content_clean, content_date_cols)\n",
    "\n",
    "# Verificar que las fechas se han convertido correctamente\n",
    "print(\"=== VERIFICACIÓN DE CONVERSIÓN DE FECHAS ===\")\n",
    "\n",
    "print(\"\\n--- USUARIOS ---\")\n",
    "print(\"Antes de la conversión:\")\n",
    "print(users['signup_date'].head())\n",
    "print(users['signup_date'].dtype)\n",
    "print(\"\\nDespués de la conversión:\")\n",
    "print(users_clean['signup_date'].head())\n",
    "print(users_clean['signup_date'].dtype)\n",
    "\n",
    "print(\"\\n--- CAMPAÑAS ---\")\n",
    "print(\"Antes de la conversión:\")\n",
    "print(campaigns['start_date'].head())\n",
    "print(campaigns['start_date'].dtype)\n",
    "print(\"\\nDespués de la conversión:\")\n",
    "print(campaigns_clean['start_date'].head())\n",
    "print(campaigns_clean['start_date'].dtype)\n",
    "\n",
    "print(\"\\n--- CONTENIDO ---\")\n",
    "print(\"Antes de la conversión:\")\n",
    "print(content['publish_date'].head())\n",
    "print(content['publish_date'].dtype)\n",
    "print(\"\\nDespués de la conversión:\")\n",
    "print(content_clean['publish_date'].head())\n",
    "print(content_clean['publish_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Duplicados\n",
    "\n",
    "Esta etapa identifica y elimina registros duplicados en los datasets, enfocándose particularmente en el dataset de engagement donde se encontraron duplicados.\n",
    "\n",
    "El proceso utiliza la función `remove_duplicates` que:\n",
    "- Identifica duplicados basados en columnas clave específicas para cada dataset\n",
    "- Proporciona información detallada sobre grupos de duplicados encontrados\n",
    "- Elimina duplicados manteniendo el primer registro por defecto (`keep='first'`)\n",
    "\n",
    "En el análisis realizado:\n",
    "- Se detectaron 2 duplicados en el dataset de **engagement** (2 grupos donde el mismo usuario interactuó con el mismo contenido)\n",
    "- Estos duplicados fueron eliminados, preservando solo el primer registro de cada grupo\n",
    "- Los demás datasets no presentaron registros duplicados en sus claves primarias\n",
    "\n",
    "La eliminación de duplicados garantiza la integridad de los datos para análisis posteriores, evitando sesgos en métricas de comportamiento de usuario y relaciones entre entidades.\n",
    "\n",
    "Nota: Aunque la función `remove_duplicates` tiene capacidad para consolidar duplicados sumando valores numéricos, en este análisis se optó por la eliminación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN DE DUPLICADOS ===\n",
      "\n",
      "--- USUARIOS ---\n",
      "Número de duplicados en user_id: 0\n",
      "\n",
      "--- ACTIVIDAD ---\n",
      "Número de duplicados en user_id: 0\n",
      "\n",
      "--- CAMPAÑAS ---\n",
      "Número de duplicados en campaign_id: 0\n",
      "\n",
      "--- CONTENIDO ---\n",
      "Número de duplicados en content_id: 0\n",
      "\n",
      "--- ENGAGEMENT ---\n",
      "Número de duplicados en user_id+content_id: 2\n",
      "🔍 Se encontraron 2 registros duplicados en 2 grupos.\n",
      "\n",
      "⚠️ Duplicados encontrados:\n",
      "    user_id content_id  likes  shares  comments\n",
      "74    U0020      C0257      1       0         1\n",
      "450   U0020      C0257      5       1         2\n",
      "--------------------------------------------------\n",
      "\n",
      "⚠️ Duplicados encontrados:\n",
      "    user_id content_id  likes  shares  comments\n",
      "81    U0146      C0126      3       1         1\n",
      "350   U0146      C0126      4       0         2\n",
      "--------------------------------------------------\n",
      "Duplicados eliminados en engagement\n",
      "\n",
      "=== RECUENTO DE REGISTROS DESPUÉS DE ELIMINAR DUPLICADOS ===\n",
      "users_clean: 200 registros\n",
      "activity_clean: 200 registros\n",
      "campaigns_clean: 5 registros\n",
      "content_clean: 300 registros\n",
      "engagement_clean: 2 registros\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicados en los dataframes y eliminarlos si es necesario\n",
    "\n",
    "# Verificar duplicados por user_id en users\n",
    "print(\"=== VERIFICACIÓN DE DUPLICADOS ===\")\n",
    "print(\"\\n--- USUARIOS ---\")\n",
    "print(f\"Número de duplicados en user_id: {users_clean.duplicated(subset=['user_id']).sum()}\")\n",
    "\n",
    "# Verificar duplicados por user_id en activity\n",
    "print(\"\\n--- ACTIVIDAD ---\")\n",
    "print(f\"Número de duplicados en user_id: {activity_clean.duplicated(subset=['user_id']).sum()}\")\n",
    "\n",
    "# Verificar duplicados por campaign_id en campaigns\n",
    "print(\"\\n--- CAMPAÑAS ---\")\n",
    "print(f\"Número de duplicados en campaign_id: {campaigns_clean.duplicated(subset=['campaign_id']).sum()}\")\n",
    "\n",
    "# Verificar duplicados por content_id en content\n",
    "print(\"\\n--- CONTENIDO ---\")\n",
    "print(f\"Número de duplicados en content_id: {content_clean.duplicated(subset=['content_id']).sum()}\")\n",
    "\n",
    "# Verificar duplicados en engagement (combinación de user_id y content_id)\n",
    "print(\"\\n--- ENGAGEMENT ---\")\n",
    "print(f\"Número de duplicados en user_id+content_id: {engagement_clean.duplicated(subset=['user_id', 'content_id']).sum()}\")\n",
    "\n",
    "# Eliminar duplicados si es necesario\n",
    "if users_clean.duplicated(subset=['user_id']).sum() > 0:\n",
    "    users_clean = remove_duplicates(users_clean, subset=['user_id'])\n",
    "    print(\"Duplicados eliminados en users\")\n",
    "\n",
    "if activity_clean.duplicated(subset=['user_id']).sum() > 0:\n",
    "    activity_clean = remove_duplicates(activity_clean, subset=['user_id'])\n",
    "    print(\"Duplicados eliminados en activity\")\n",
    "\n",
    "if campaigns_clean.duplicated(subset=['campaign_id']).sum() > 0:\n",
    "    campaigns_clean = remove_duplicates(campaigns_clean, subset=['campaign_id'])\n",
    "    print(\"Duplicados eliminados en campaigns\")\n",
    "\n",
    "if content_clean.duplicated(subset=['content_id']).sum() > 0:\n",
    "    content_clean = remove_duplicates(content_clean, subset=['content_id'])\n",
    "    print(\"Duplicados eliminados en content\")\n",
    "\n",
    "if engagement_clean.duplicated(subset=['user_id', 'content_id']).sum() > 0:\n",
    "    engagement_clean = remove_duplicates(engagement_clean, subset=['user_id', 'content_id'])\n",
    "    print(\"Duplicados eliminados en engagement\")\n",
    "\n",
    "# Verificar la cantidad de registros después de eliminar duplicados\n",
    "print(\"\\n=== RECUENTO DE REGISTROS DESPUÉS DE ELIMINAR DUPLICADOS ===\")\n",
    "print(f\"users_clean: {len(users_clean)} registros\")\n",
    "print(f\"activity_clean: {len(activity_clean)} registros\")\n",
    "print(f\"campaigns_clean: {len(campaigns_clean)} registros\")\n",
    "print(f\"content_clean: {len(content_clean)} registros\")\n",
    "print(f\"engagement_clean: {len(engagement_clean)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Corrección de Inconsistencias Temporales\n",
    "\n",
    "Esta etapa identifica y corrige inconsistencias lógicas en los datos temporales, específicamente usuarios cuya fecha de última actividad es anterior a su fecha de registro. \n",
    "\n",
    "La metodología implementada utiliza la función `fix_temporal_inconsistencies` que:\n",
    "- Calcula la diferencia en días entre la última actividad y el registro\n",
    "- Identifica registros con diferencias negativas (inconsistencias lógicas)\n",
    "- Ajusta la fecha de registro para que coincida con la fecha de última actividad\n",
    "\n",
    "Este enfoque de corrección se basa en las siguientes premisas:\n",
    "1. Los datos de actividad suelen ser más precisos que los de registro\n",
    "2. Se preservan todos los registros evitando sesgos en métricas \n",
    "3. Se siguen recomendaciones de estudios recientes sobre análisis de engagement\n",
    "\n",
    "Se identificaron y corrigieron 6 registros con inconsistencias temporales, donde la fecha de última actividad era anterior a la fecha de registro. En vez de eliminar estos registros, se ajustó la fecha de registro al valor de la última actividad, asumiendo que esta representa la primera interacción real del usuario con la plataforma.\n",
    "\n",
    "Esta corrección metodológica es fundamental para análisis de retención y comportamiento a lo largo del tiempo, garantizando que las métricas de permanencia y actividad sean lógicamente consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros con fechas inconsistentes (última actividad anterior al registro):\n",
      "    user_id    country signup_date last_active  gender  age  days_active\n",
      "5     U0005     México  2025-03-11  2025-03-05  Female   32           -6\n",
      "14    U0014      Chile  2025-03-12  2025-03-01  Female   34          -11\n",
      "53    U0053       Perú  2025-03-02  2025-03-01  Female   38           -1\n",
      "113   U0113   Colombia  2025-03-07  2025-03-04  Female   51           -3\n",
      "161   U0161  Argentina  2025-03-09  2025-03-05  Female   43           -4\n",
      "198   U0198       Perú  2025-03-10  2025-03-07   Other   47           -3\n",
      "\n",
      "Total de registros inconsistentes: 6\n",
      "🔍 Se encontraron 6 registros con inconsistencias temporales.\n",
      "\n",
      "⚠️ Ejemplos de inconsistencias:\n",
      "    user_id signup_date last_active  days_active\n",
      "5     U0005  2025-03-11  2025-03-05           -6\n",
      "14    U0014  2025-03-12  2025-03-01          -11\n",
      "53    U0053  2025-03-02  2025-03-01           -1\n",
      "113   U0113  2025-03-07  2025-03-04           -3\n",
      "161   U0161  2025-03-09  2025-03-05           -4\n",
      "\n",
      "✅ Inconsistencias temporales corregidas. Registros afectados: 6\n",
      "Registros con días activos negativos después de corrección: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular días activos y mostrar inconsistencias antes de corregir\n",
    "users_clean['days_active'] = (users_clean['last_active'] - users_clean['signup_date']).dt.days\n",
    "usuarios_inconsistentes = users_clean[users_clean['days_active'] < 0].copy()\n",
    "\n",
    "# Mostrar registros problemáticos\n",
    "print(\"Registros con fechas inconsistentes (última actividad anterior al registro):\")\n",
    "print(usuarios_inconsistentes[['user_id', 'country', 'signup_date', 'last_active', 'gender', 'age', 'days_active']])\n",
    "print(f\"\\nTotal de registros inconsistentes: {len(usuarios_inconsistentes)}\")\n",
    "\n",
    "# 2. Aplicar corrección metodológica usando la función modularizada\n",
    "users_clean = fix_temporal_inconsistencies(users_clean, 'signup_date', 'last_active', verbose=True)\n",
    "\n",
    "# 3. Verificar corrección\n",
    "print(f\"Registros con días activos negativos después de corrección: {len(users_clean[users_clean['days_active'] < 0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Tratamiento de Outliers\n",
    "\n",
    "Esta etapa identifica y trata valores atípicos (outliers) en las variables numéricas de los datasets. Se implementa un enfoque de winsorización selectiva mediante la función `process_outliers` que:\n",
    "\n",
    "- Aplica factores específicos por columna para definir umbrales de detección\n",
    "- Utiliza el método de Rango Intercuartílico (IQR) multiplicado por factores configurables\n",
    "- Reemplaza valores extremos por los límites definidos en lugar de eliminarlos\n",
    "- Preserva la distribución general de los datos sin perder observaciones\n",
    "\n",
    "La configuración aplicada utiliza diferentes factores según el tipo de variable:\n",
    "- Métricas de actividad (`avg_daily_visits`): factor IQR de 3.0\n",
    "- Visitas a contenido (`visits`): factor IQR de 3.0\n",
    "- Métricas de engagement (`likes`, `shares`, `comments`): factor IQR de 4.0\n",
    "\n",
    "Esta estrategia diferenciada refleja la naturaleza específica de cada variable:\n",
    "- Mayor tolerancia (factor 4.0) para métricas de engagement donde la variabilidad es esperada\n",
    "- Menor tolerancia (factor 3.0) para métricas de actividad y visitas\n",
    "\n",
    "El análisis no identificó outliers según estos criterios, lo que indica que los datos ya presentaban distribuciones razonablemente consistentes dentro de los umbrales establecidos.\n",
    "\n",
    "Esta etapa es crucial para garantizar que análisis estadísticos posteriores no se vean distorsionados por valores extremos, manteniendo la robustez de los resultados analíticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🔍 TRATAMIENTO DE OUTLIERS (MEJORES PRÁCTICAS) ===\n",
      "\n",
      "--- 📋 USERS ---\n",
      "\n",
      "--- 📋 ACTIVITY ---\n",
      "\n",
      "--- 📊 ACTIVITY (AVG_DAILY_VISITS) ---\n",
      "\n",
      "📊 Estadísticas de avg_daily_visits antes de winsorización:\n",
      "count    200.000000\n",
      "mean       1.551700\n",
      "std        0.852482\n",
      "min        0.200000\n",
      "25%        0.810000\n",
      "50%        1.480000\n",
      "75%        2.275000\n",
      "max        2.990000\n",
      "Name: avg_daily_visits, dtype: float64\n",
      "🔍 Límites para outliers (IQR x 3.0): -3.58 - 6.67\n",
      "🔢 Número de outliers detectados: 0\n",
      "✅ No se detectaron outliers.\n",
      "\n",
      "--- 📋 CAMPAIGNS ---\n",
      "\n",
      "--- 📋 CONTENT ---\n",
      "\n",
      "--- 📊 CONTENT (VISITS) ---\n",
      "\n",
      "📊 Estadísticas de visits antes de winsorización:\n",
      "count    300.000000\n",
      "mean      50.016667\n",
      "std        6.954442\n",
      "min       33.000000\n",
      "25%       45.000000\n",
      "50%       50.000000\n",
      "75%       55.000000\n",
      "max       74.000000\n",
      "Name: visits, dtype: float64\n",
      "🔍 Límites para outliers (IQR x 3.0): 15.00 - 85.00\n",
      "🔢 Número de outliers detectados: 0\n",
      "✅ No se detectaron outliers.\n",
      "\n",
      "--- 📋 ENGAGEMENT ---\n",
      "\n",
      "--- 📊 ENGAGEMENT (LIKES) ---\n",
      "\n",
      "📊 Estadísticas de likes antes de winsorización:\n",
      "count    498.000000\n",
      "mean       2.058233\n",
      "std        1.450256\n",
      "min        0.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        3.000000\n",
      "max        9.000000\n",
      "Name: likes, dtype: float64\n",
      "🔍 Límites para outliers (IQR x 4.0): -7.00 - 11.00\n",
      "🔢 Número de outliers detectados: 0\n",
      "✅ No se detectaron outliers.\n",
      "\n",
      "--- 📊 ENGAGEMENT (SHARES) ---\n",
      "\n",
      "📊 Estadísticas de shares antes de winsorización:\n",
      "count    498.000000\n",
      "mean       0.273092\n",
      "std        0.445996\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: shares, dtype: float64\n",
      "🔍 Límites para outliers (IQR x 4.0): -4.00 - 5.00\n",
      "🔢 Número de outliers detectados: 0\n",
      "✅ No se detectaron outliers.\n",
      "\n",
      "--- 📊 ENGAGEMENT (COMMENTS) ---\n",
      "\n",
      "📊 Estadísticas de comments antes de winsorización:\n",
      "count    498.000000\n",
      "mean       0.975904\n",
      "std        0.951236\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        2.000000\n",
      "max        5.000000\n",
      "Name: comments, dtype: float64\n",
      "🔍 Límites para outliers (IQR x 4.0): -8.00 - 10.00\n",
      "🔢 Número de outliers detectados: 0\n",
      "✅ No se detectaron outliers.\n",
      "\n",
      "=== ✅ RECUENTO DE REGISTROS FINAL ===\n",
      "📋 users: 200 registros\n",
      "📋 activity: 200 registros\n",
      "📋 campaigns: 5 registros\n",
      "📋 content: 300 registros\n",
      "📋 engagement: 498 registros\n"
     ]
    }
   ],
   "source": [
    "# Corregir la estructura de los DataFrames si son tuplas\n",
    "dfs = {'users': users_clean, 'activity': activity_clean, 'campaigns': campaigns_clean, \n",
    "       'content': content_clean, 'engagement': engagement_clean}\n",
    "\n",
    "# Desempaquetar cualquier tupla (resultados de remove_duplicates)\n",
    "for key in dfs:\n",
    "    if isinstance(dfs[key], tuple):\n",
    "        dfs[key], _ = dfs[key]\n",
    "\n",
    "# Definir factores específicos para cada columna\n",
    "column_factors = {\n",
    "    'activity': {'avg_daily_visits': 3.0},\n",
    "    'content': {'visits': 3.0},\n",
    "    'engagement': {'likes': 4.0, 'shares': 4.0, 'comments': 4.0}\n",
    "}\n",
    "\n",
    "# Procesar outliers en todos los DataFrames y obtener resultados finales\n",
    "clean_dfs = process_outliers(dfs, column_factors)\n",
    "\n",
    "# Asignar los DataFrames limpios a variables individuales\n",
    "users_clean_final = clean_dfs['users']\n",
    "activity_clean_final = clean_dfs['activity']\n",
    "campaigns_clean_final = clean_dfs['campaigns']\n",
    "content_clean_final = clean_dfs['content']\n",
    "engagement_clean_final = clean_dfs['engagement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Almacenamiento de Datos Procesados\n",
    "\n",
    "En esta etapa final se guardan los datasets limpios y procesados para su uso en análisis posteriores. Se utiliza la función `save_processed_data` que:\n",
    "\n",
    "- Almacena cada dataset en formato CSV con codificación UTF-8\n",
    "- Aplica una nomenclatura estandarizada (prefijo \"peliplat_\" y sufijo \"_clean\")\n",
    "- Genera la estructura de directorios necesaria si no existe\n",
    "- Proporciona confirmación detallada del proceso de guardado\n",
    "\n",
    "Los datasets procesados y guardados son:\n",
    "- `peliplat_users_clean.csv`: 200 registros\n",
    "- `peliplat_activity_clean.csv`: 200 registros\n",
    "- `peliplat_campaigns_clean.csv`: 5 registros\n",
    "- `peliplat_content_clean.csv`: 300 registros\n",
    "- `peliplat_engagement_clean.csv`: 498 registros\n",
    "\n",
    "Estos archivos constituyen la base para el análisis exploratorio avanzado y modelado, cumpliendo con los requisitos de calidad de datos establecidos:\n",
    "- Codificación correcta de caracteres especiales\n",
    "- Fechas en formato datetime estandarizado\n",
    "- Eliminación de duplicados innecesarios\n",
    "- Corrección de inconsistencias temporales\n",
    "- Tratamiento adecuado de valores extremos\n",
    "\n",
    "El almacenamiento en la carpeta `data/processed/` sigue las convenciones de organización de proyectos de análisis de datos, separando claramente datos crudos de datos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Guardado exitoso: peliplat_users_clean.csv (200 registros)\n",
      "✅ Guardado exitoso: peliplat_activity_clean.csv (200 registros)\n",
      "✅ Guardado exitoso: peliplat_campaigns_clean.csv (5 registros)\n",
      "✅ Guardado exitoso: peliplat_content_clean.csv (300 registros)\n",
      "✅ Guardado exitoso: peliplat_engagement_clean.csv (498 registros)\n",
      "\n",
      "📂 Archivos guardados en: C:\\Users\\trico\\Desktop\\Prueba cine proyecto\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario con los DataFrames limpios finales\n",
    "dfs_limpios = {\n",
    "    'users': users_clean_final,\n",
    "    'activity': activity_clean_final, \n",
    "    'campaigns': campaigns_clean_final,\n",
    "    'content': content_clean_final,\n",
    "    'engagement': engagement_clean_final\n",
    "}\n",
    "\n",
    "# Guardar todos los DataFrames en la carpeta data/processed/\n",
    "archivos_guardados = save_processed_data(dfs_limpios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
